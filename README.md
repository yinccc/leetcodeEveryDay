# leetcodeEveryDay
##2019年3月13日面经总结 成都招行信用卡中心
1.怎么防止过拟合

2.L1正则和L2正则的联系与区别

3.ID3树用什么指标选择特征

4.开放题，预测一位学生期末是否挂科，需要挖掘哪些信息

第一题答案：
1.增加数据量
2.训练提前终止(early_stopping)
3.正则化(L1 L2)
4.减小模型复杂度
5.神经网络可以用dropout

第二题答案：
L1正则和L2正则都可以防止过拟合，L1正则化的解具有稀疏性，可以用于特征选择，
L2正则化的解都比较小，比较平滑。

第三题答案：
ID3书选择特征的指标为信息增益

第四题答案：
比如平时作业完成情况分类，上课回答问题情况，半期考试成绩等等

##2019年3月15日面经总结 招行信用卡中心
###一面
1.对图像处理有兴趣么 华为实习三个项目

2.L1,L2正则化和区别

3.XGBoost和提升树

第三题答案
XGBoost：总的误差来源于两个方面，训练误差与正则项误差。XGBoost中，在第t轮添加新模型的时候，为了使得总的误差
最小，使用了泰勒展开式，取了一阶和二阶导数。正则项误差定义模型复杂度，太复杂的模型可能过拟合，于是正则项误差包括
叶子节点的数目和。。。。。

提升树(boosting tree)包括catboost,lightgbm,xgboost和gbdt，基本原理是使用第一轮的残差作为第二轮的目标函数，继续进行训练。

###二面
1.三个项目

2.怎么学的算法

3.为什么学算法

4.觉得自己是什么样的人

5.对华为的看法

6.有什么想问的

第二题：吴恩达的deep learning系列入门，上kaggle看kernel，做比赛，看论文

第三题：因为前景好

##2019年3月22日